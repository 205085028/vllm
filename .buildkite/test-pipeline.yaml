steps:
- label: Regression Test
  command: pytest -v -s test_regression.py
  working_dir: "/vllm-workspace/tests" # optional

- label: AsyncEngine Test
  command: pytest -v -s async_engine

- label: Distributed Test
  command: pytest -v -s test_comm_ops.py
  working_dir: "/vllm-workspace/tests/distributed"
  num_gpus: 2 # only support 1 or 2 for now.

- label: Engine Test
  command: pytest -v -s engine

- label: Kernels Test
  command: pytest -v -s kernels

- label: Models Test
  commands:
    - pip install einops # required for MPT
    - pip install flash_attn # required for HuggingFace's llama implementation
    - pytest -v -s models --forked

- label: Samplers Test
  command: pytest -v -s samplers --forked

- label: Worker Test
  command: pytest -v -s worker

- label: Benchmarks
  working_dir: "/vllm-workspace/.buildkite"
  commands:
  - pip install aiohttp
  - bash run-benchmarks.sh