---
MainSourceFile:  MainSrcFiles_placehold
Replacements:
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          868
    Length:          0
    ReplacementText: "#include <sycl/sycl.hpp>\n#include <dpct/dpct.hpp>\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          963
    Length:          30
    ReplacementText: '#include "attention_utils.dp.hpp"'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          1269
    Length:          11
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          1322
    Length:          0
    ReplacementText: ",\n                       const sycl::nd_item<3> &item_ct1"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          1389
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          1427
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          1556
    Length:          0
    ReplacementText: "    /*\n    DPCT1023:2: The SYCL sub-group does not support mask options for dpct::permute_sub_group_by_xor.\n    */\n    /*\n    DPCT1096:42: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::permute_sub_group_by_xor\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n    */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          1567
    Length:          40
    ReplacementText: 'dpct::permute_sub_group_by_xor(item_ct1.get_sub_group(), sum, mask)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          1762
    Length:          15
    ReplacementText: "/*\n  DPCT1065:1: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n  */\n  item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          1989
    Length:          0
    ReplacementText: "    /*\n    DPCT1023:3: The SYCL sub-group does not support mask options for dpct::permute_sub_group_by_xor.\n    */\n    /*\n    DPCT1096:43: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::permute_sub_group_by_xor\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n    */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          2000
    Length:          40
    ReplacementText: 'dpct::permute_sub_group_by_xor(item_ct1.get_sub_group(), sum, mask)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          2080
    Length:          0
    ReplacementText: "  /*\n  DPCT1023:4: The SYCL sub-group does not support mask options for dpct::select_from_sub_group.\n  */\n  /*\n  DPCT1096:44: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::select_from_sub_group\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n  */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          2089
    Length:          33
    ReplacementText: 'dpct::select_from_sub_group(item_ct1.get_sub_group(), sum, 0)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          2381
    Length:          11
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          3350
    Length:          0
    ReplacementText: ",\n  const sycl::nd_item<3> &item_ct1,\n  uint8_t *dpct_local,\n  sycl::local_accessor<Q_vec, 2> q_vecs,\n  float *red_smem"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          3376
    Length:          10
    ReplacementText: 'item_ct1.get_group(1)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          3416
    Length:          10
    ReplacementText: 'item_ct1.get_group(0)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          3461
    Length:          9
    ReplacementText: 'item_ct1.get_group_range(0)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          4917
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          5044
    Length:          10
    ReplacementText: 'item_ct1.get_group(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          5080
    Length:          9
    ReplacementText: 'item_ct1.get_group_range(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          6489
    Length:          64
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          6826
    Length:          15
    ReplacementText: "/*\n  DPCT1065:5: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n  */\n  item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          6968
    Length:          36
    ReplacementText: 'auto shared_mem = (char *)dpct_local;'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          7168
    Length:          41
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          9927
    Length:          17
    ReplacementText: 'sycl::fmax(qk_max, qk)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          10264
    Length:          0
    ReplacementText: "    /*\n    DPCT1023:9: The SYCL sub-group does not support mask options for dpct::permute_sub_group_by_xor.\n    */\n    /*\n    DPCT1096:38: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::permute_sub_group_by_xor\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n    */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          10277
    Length:          58
    ReplacementText: 'sycl::fmax(qk_max, dpct::permute_sub_group_by_xor(item_ct1.get_sub_group(), qk_max, mask))'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          10399
    Length:          15
    ReplacementText: "/*\n  DPCT1065:6: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n  */\n  item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          10629
    Length:          0
    ReplacementText: "    /*\n    DPCT1023:10: The SYCL sub-group does not support mask options for dpct::permute_sub_group_by_xor.\n    */\n    /*\n    DPCT1096:39: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::permute_sub_group_by_xor\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n    */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          10642
    Length:          58
    ReplacementText: 'sycl::fmax(qk_max, dpct::permute_sub_group_by_xor(item_ct1.get_sub_group(), qk_max, mask))'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          10754
    Length:          0
    ReplacementText: "  /*\n  DPCT1023:11: The SYCL sub-group does not support mask options for dpct::select_from_sub_group.\n  */\n  /*\n  DPCT1096:40: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::select_from_sub_group\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n  */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          10765
    Length:          36
    ReplacementText: 'dpct::select_from_sub_group(item_ct1.get_sub_group(), qk_max, 0)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          10942
    Length:          26
    ReplacementText: 'sycl::exp(logits[i] - qk_max)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          11077
    Length:          0
    ReplacementText: ', item_ct1'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          11127
    Length:          32
    ReplacementText: '1.f / (exp_sum + 1e-6f)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          11256
    Length:          15
    ReplacementText: "/*\n  DPCT1065:7: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n  */\n  item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          14590
    Length:          0
    ReplacementText: "      /*\n      DPCT1023:12: The SYCL sub-group does not support mask options for dpct::permute_sub_group_by_xor.\n      */\n      /*\n      DPCT1096:41: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::permute_sub_group_by_xor\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n      */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          14603
    Length:          40
    ReplacementText: 'dpct::permute_sub_group_by_xor(item_ct1.get_sub_group(), acc, mask)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          14792
    Length:          15
    ReplacementText: "/*\n  DPCT1065:8: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n  */\n  item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          15409
    Length:          15
    ReplacementText: "/*\n    DPCT1065:13: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n    */\n    item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          15829
    Length:          15
    ReplacementText: "/*\n    DPCT1065:14: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n    */\n    item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          16518
    Length:          11
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          17296
    Length:          0
    ReplacementText: ",\n  const sycl::nd_item<3> &item_ct1,\n  uint8_t *dpct_local,\n  sycl::local_accessor<Q_vec, 2> q_vecs,\n  float *red_smem"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          17588
    Length:          0
    ReplacementText: ', item_ct1, dpct_local, q_vecs, red_smem'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          17753
    Length:          11
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          18725
    Length:          0
    ReplacementText: ",\n  const sycl::nd_item<3> &item_ct1,\n  uint8_t *dpct_local,\n  sycl::local_accessor<Q_vec, 2> q_vecs,\n  float *red_smem"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          19009
    Length:          0
    ReplacementText: ', item_ct1, dpct_local, q_vecs, red_smem'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          19136
    Length:          11
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          19622
    Length:          0
    ReplacementText: ",\n  const sycl::nd_item<3> &item_ct1,\n  uint8_t *dpct_local,\n  float *red_smem"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          19650
    Length:          9
    ReplacementText: 'item_ct1.get_group_range(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          19684
    Length:          10
    ReplacementText: 'item_ct1.get_group(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          19718
    Length:          10
    ReplacementText: 'item_ct1.get_group(1)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          20222
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          20255
    Length:          10
    ReplacementText: 'item_ct1.get_local_range(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          20438
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          20482
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          20541
    Length:          36
    ReplacementText: 'auto shared_mem = (char *)dpct_local;'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          20610
    Length:          41
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          20966
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21004
    Length:          10
    ReplacementText: 'item_ct1.get_local_range(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21103
    Length:          19
    ReplacementText: 'sycl::fmax(max_logit, (float)l)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21130
    Length:          15
    ReplacementText: "/*\n  DPCT1065:15: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n  */\n  item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21280
    Length:          0
    ReplacementText: "    /*\n    DPCT1023:18: The SYCL sub-group does not support mask options for dpct::permute_sub_group_by_xor.\n    */\n    /*\n    DPCT1096:45: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::permute_sub_group_by_xor\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n    */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21296
    Length:          64
    ReplacementText: 'sycl::fmax(max_logit, dpct::permute_sub_group_by_xor(item_ct1.get_sub_group(), max_logit, mask))'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21427
    Length:          15
    ReplacementText: "/*\n  DPCT1065:16: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n  */\n  item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21602
    Length:          0
    ReplacementText: "    /*\n    DPCT1023:19: The SYCL sub-group does not support mask options for dpct::permute_sub_group_by_xor.\n    */\n    /*\n    DPCT1096:46: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::permute_sub_group_by_xor\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n    */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21618
    Length:          64
    ReplacementText: 'sycl::fmax(max_logit, dpct::permute_sub_group_by_xor(item_ct1.get_sub_group(), max_logit, mask))'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21733
    Length:          0
    ReplacementText: "  /*\n  DPCT1023:20: The SYCL sub-group does not support mask options for dpct::select_from_sub_group.\n  */\n  /*\n  DPCT1096:47: The right-most dimension of the work-group used in the SYCL kernel that calls this function may be less than \"32\". The function \"dpct::select_from_sub_group\" may return an unexpected result on the CPU device. Modify the size of the work-group to ensure that the value of the right-most dimension is a multiple of \"32\".\n  */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          21747
    Length:          39
    ReplacementText: 'dpct::select_from_sub_group(item_ct1.get_sub_group(), max_logit, 0)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          22133
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          22171
    Length:          10
    ReplacementText: 'item_ct1.get_local_range(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          22268
    Length:          19
    ReplacementText: 'sycl::exp(l - max_logit)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          22378
    Length:          15
    ReplacementText: "/*\n  DPCT1065:17: Consider replacing sycl::nd_item::barrier() with sycl::nd_item::barrier(sycl::access::fence_space::local_space) for better performance if there is no access to global memory.\n  */\n  item_ct1.barrier()"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          22471
    Length:          0
    ReplacementText: ', item_ct1'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          22509
    Length:          40
    ReplacementText: '1.0f / (global_exp_sum + 1e-6f)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          22877
    Length:          11
    ReplacementText: 'item_ct1.get_local_id(2)'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          23158
    Length:          0
    ReplacementText: "/*\nDPCT1049:21: The work-group size passed to the SYCL kernel may exceed the limit. To get the device limit, query info::device::max_work_group_size. Adjust the work-group size if needed.\n*/\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          23544
    Length:          1361
    ReplacementText: "stream->submit(\\\n  [&](sycl::handler &cgh) {\\\n    sycl::local_accessor<uint8_t, 1> dpct_local_acc_ct1(sycl::range<1>(shared_mem_size), cgh);\\\n    sycl::local_accessor<Q_vec, 2> q_vecs_acc_ct1(sycl::range<2>(THREAD_GROUP_SIZE, NUM_VECS_PER_THREAD), cgh);\\\n    sycl::local_accessor<float, 1> red_smem_acc_ct1(sycl::range<1>(2 * NUM_WARPS), cgh);\\\n\\\n    auto out_ptr_ct0 = out_ptr;\\\n    auto query_ptr_ct1 = query_ptr;\\\n    auto key_cache_ptr_ct2 = key_cache_ptr;\\\n    auto value_cache_ptr_ct3 = value_cache_ptr;\\\n    auto head_mapping_ptr_ct4 = head_mapping_ptr;\\\n    auto scale_ct5 = scale;\\\n    auto block_tables_ptr_ct6 = block_tables_ptr;\\\n    auto context_lens_ptr_ct7 = context_lens_ptr;\\\n    auto max_num_blocks_per_seq_ct8 = max_num_blocks_per_seq;\\\n    auto alibi_slopes_ptr_ct9 = alibi_slopes_ptr;\\\n    auto q_stride_ct10 = q_stride;\\\n    auto kv_block_stride_ct11 = kv_block_stride;\\\n    auto kv_head_stride_ct12 = kv_head_stride;\\\n\\\n    cgh.parallel_for(\\\n      sycl::nd_range<3>(grid * block, block), \\\n      [=](sycl::nd_item<3> item_ct1) [[intel::reqd_sub_group_size(32)]] {\\\n        vllm::paged_attention_v1_kernel<T, HEAD_SIZE, BLOCK_SIZE, NUM_THREADS>(out_ptr_ct0, query_ptr_ct1, key_cache_ptr_ct2, value_cache_ptr_ct3, head_mapping_ptr_ct4, scale_ct5, block_tables_ptr_ct6, context_lens_ptr_ct7, max_num_blocks_per_seq_ct8, alibi_slopes_ptr_ct9, q_stride_ct10, kv_block_stride_ct11, kv_head_stride_ct12, item_ct1, dpct_local_acc_ct1.get_pointer(), q_vecs_acc_ct1, red_smem_acc_ct1.get_pointer());\\\n      });\\\n  });"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: true
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          24905
    Length:          1
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          26458
    Length:          0
    ReplacementText: "  /*\n  DPCT1083:22: The size of local memory in the migrated code may be different from the original code. Check that the allocated memory size in the migrated code is correct.\n  */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          26771
    Length:          4
    ReplacementText: 'sycl::range<3>'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          26781
    Length:          22
    ReplacementText: 1, num_seqs, num_heads
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          26808
    Length:          4
    ReplacementText: 'sycl::range<3>'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          26819
    Length:          11
    ReplacementText: 1, 1, NUM_THREADS
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          26841
    Length:          12
    ReplacementText: 'dpct::queue_ptr'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          30381
    Length:          13
    ReplacementText: 'oneapi::mkl::bfloat16'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          30481
    Length:          0
    ReplacementText: "/*\nDPCT1049:23: The work-group size passed to the SYCL kernel may exceed the limit. To get the device limit, query info::device::max_work_group_size. Adjust the work-group size if needed.\n*/\n/*\nDPCT1049:25: The work-group size passed to the SYCL kernel may exceed the limit. To get the device limit, query info::device::max_work_group_size. Adjust the work-group size if needed.\n*/\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          30579
    Length:          1553
    ReplacementText: "stream->submit(\\\n  [&](sycl::handler &cgh) {\\\n    sycl::local_accessor<uint8_t, 1> dpct_local_acc_ct1(sycl::range<1>(shared_mem_size), cgh);\\\n    sycl::local_accessor<Q_vec, 2> q_vecs_acc_ct1(sycl::range<2>(THREAD_GROUP_SIZE, NUM_VECS_PER_THREAD), cgh);\\\n    sycl::local_accessor<float, 1> red_smem_acc_ct1(sycl::range<1>(2 * NUM_WARPS), cgh);\\\n\\\n    auto exp_sums_ptr_ct0 = exp_sums_ptr;\\\n    auto max_logits_ptr_ct1 = max_logits_ptr;\\\n    auto tmp_out_ptr_ct2 = tmp_out_ptr;\\\n    auto query_ptr_ct3 = query_ptr;\\\n    auto key_cache_ptr_ct4 = key_cache_ptr;\\\n    auto value_cache_ptr_ct5 = value_cache_ptr;\\\n    auto head_mapping_ptr_ct6 = head_mapping_ptr;\\\n    auto scale_ct7 = scale;\\\n    auto block_tables_ptr_ct8 = block_tables_ptr;\\\n    auto context_lens_ptr_ct9 = context_lens_ptr;\\\n    auto max_num_blocks_per_seq_ct10 = max_num_blocks_per_seq;\\\n    auto alibi_slopes_ptr_ct11 = alibi_slopes_ptr;\\\n    auto q_stride_ct12 = q_stride;\\\n    auto kv_block_stride_ct13 = kv_block_stride;\\\n    auto kv_head_stride_ct14 = kv_head_stride;\\\n\\\n    cgh.parallel_for(\\\n      sycl::nd_range<3>(grid * block, block), \\\n      [=](sycl::nd_item<3> item_ct1) [[intel::reqd_sub_group_size(32)]] {\\\n        vllm::paged_attention_v2_kernel<T, HEAD_SIZE, BLOCK_SIZE, NUM_THREADS, PARTITION_SIZE>(exp_sums_ptr_ct0, max_logits_ptr_ct1, tmp_out_ptr_ct2, query_ptr_ct3, key_cache_ptr_ct4, value_cache_ptr_ct5, head_mapping_ptr_ct6, scale_ct7, block_tables_ptr_ct8, context_lens_ptr_ct9, max_num_blocks_per_seq_ct10, alibi_slopes_ptr_ct11, q_stride_ct12, kv_block_stride_ct13, kv_head_stride_ct14, item_ct1, dpct_local_acc_ct1.get_pointer(), q_vecs_acc_ct1, red_smem_acc_ct1.get_pointer());\\\n      });\\\n  });"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: true
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          32132
    Length:          1
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          32211
    Length:          693
    ReplacementText: "stream->submit(\\\n  [&](sycl::handler &cgh) {\\\n    sycl::local_accessor<uint8_t, 1> dpct_local_acc_ct1(sycl::range<1>(reduce_shared_mem_size), cgh);\\\n    sycl::local_accessor<float, 1> red_smem_acc_ct1(sycl::range<1>(2 * NUM_WARPS), cgh);\\\n\\\n    auto out_ptr_ct0 = out_ptr;\\\n    auto exp_sums_ptr_ct1 = exp_sums_ptr;\\\n    auto max_logits_ptr_ct2 = max_logits_ptr;\\\n    auto tmp_out_ptr_ct3 = tmp_out_ptr;\\\n    auto context_lens_ptr_ct4 = context_lens_ptr;\\\n    auto max_num_partitions_ct5 = max_num_partitions;\\\n\\\n    cgh.parallel_for(\\\n      sycl::nd_range<3>(reduce_grid * block, block), \\\n      [=](sycl::nd_item<3> item_ct1) [[intel::reqd_sub_group_size(32)]] {\\\n        vllm::paged_attention_v2_reduce_kernel<T, HEAD_SIZE, NUM_THREADS, PARTITION_SIZE>(out_ptr_ct0, exp_sums_ptr_ct1, max_logits_ptr_ct2, tmp_out_ptr_ct3, context_lens_ptr_ct4, max_num_partitions_ct5, item_ct1, dpct_local_acc_ct1.get_pointer(), red_smem_acc_ct1.get_pointer());\\\n      });\\\n  });"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: true
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          32904
    Length:          1
    ReplacementText: ''
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          34726
    Length:          0
    ReplacementText: "  /*\n  DPCT1083:26: The size of local memory in the migrated code may be different from the original code. Check that the allocated memory size in the migrated code is correct.\n  */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          34883
    Length:          4
    ReplacementText: 'sycl::range<3>'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          34893
    Length:          39
    ReplacementText: max_num_partitions, num_seqs, num_heads
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          35041
    Length:          4
    ReplacementText: 'sycl::range<3>'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          35058
    Length:          19
    ReplacementText: 1, num_seqs, num_heads
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          35080
    Length:          0
    ReplacementText: "  /*\n  DPCT1083:24: The size of local memory in the migrated code may be different from the original code. Check that the allocated memory size in the migrated code is correct.\n  */\n"
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          35154
    Length:          4
    ReplacementText: 'sycl::range<3>'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          35165
    Length:          11
    ReplacementText: 1, 1, NUM_THREADS
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          35187
    Length:          12
    ReplacementText: 'dpct::queue_ptr'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
  - FilePath:        '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Offset:          39185
    Length:          13
    ReplacementText: 'oneapi::mkl::bfloat16'
    ConstantFlag:    ''
    ConstantOffset:  0
    InitStr:         ''
    NewHostVarName:  ''
    BlockLevelFormatFlag: false
MainSourceFilesDigest:
  - MainSourceFile:  '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
    Digest:          3630fb4aa27671c92f2d185193b9096b
DpctVersion:     2023.1.0
MainHelperFileName: dpct
USMLevel:        ''
FeatureMap:
  device.hpp:
    typedef_queue_ptr:
      IsCalled:        true
      CallerSrcFiles:
        - '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
      FeatureName:     queue_ptr
      SubFeatureMap:   {}
  dpct.hpp:
    dpct_compatibility_temp:
      IsCalled:        true
      CallerSrcFiles:
        - '/home/majumder/vllm_proto/csrc/csrc/attention/dtype_bfloat16.cuh'
        - '/home/majumder/vllm_proto/csrc/csrc/attention/dtype_float16.cuh'
      FeatureName:     DPCT_COMPATIBILITY_TEMP
      SubFeatureMap:   {}
    non_local_include_dependency:
      IsCalled:        true
      CallerSrcFiles:
        - ''
      FeatureName:     ''
      SubFeatureMap:   {}
  util.hpp:
    permute_sub_group_by_xor:
      IsCalled:        true
      CallerSrcFiles:
        - '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
        - '/home/majumder/vllm_proto/csrc/csrc/attention/attention_utils.cuh'
      FeatureName:     permute_sub_group_by_xor
      SubFeatureMap:   {}
    select_from_sub_group:
      IsCalled:        true
      CallerSrcFiles:
        - '/home/majumder/vllm_proto/csrc/csrc/attention/attention_kernels.cu'
      FeatureName:     select_from_sub_group
      SubFeatureMap:   {}
CompileTargets:  {}
OptionMap:
  AnalysisScopePath:
    Value:           '/home/majumder/vllm_proto/csrc/csrc/attention'
    Specified:       false
  AsyncHandler:
    Value:           'false'
    Specified:       false
  CommentsEnabled:
    Value:           'false'
    Specified:       false
  CompilationsDir:
    Value:           ''
    Specified:       false
  CtadEnabled:
    Value:           'false'
    Specified:       false
  CustomHelperFileName:
    Value:           dpct
    Specified:       false
  EnablepProfiling:
    Value:           'false'
    Specified:       false
  ExperimentalFlag:
    Value:           '0'
    Specified:       false
  ExplicitClNamespace:
    Value:           'false'
    Specified:       false
  ExplicitNamespace:
    Value:           '20'
    Specified:       false
  ExtensionDDFlag:
    Value:           '0'
    Specified:       false
  ExtensionDEFlag:
    Value:           '4294967295'
    Specified:       false
  NDRangeDim:
    Value:           '3'
    Specified:       false
  NoDRYPattern:
    Value:           'false'
    Specified:       false
  OptimizeMigration:
    Value:           'false'
    Specified:       false
  ProcessAll:
    Value:           'false'
    Specified:       false
  RuleFile:
    Value:           ''
    Specified:       false
  SyclNamedLambda:
    Value:           'false'
    Specified:       false
  UsmLevel:
    Value:           '1'
    Specified:       false
...
